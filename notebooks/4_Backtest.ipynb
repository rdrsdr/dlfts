{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#Setup google-drive mounting (optional)"
      ],
      "metadata": {
        "id": "erlrIYB0q5v_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "import os\n",
        "\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "4Z3V2jwlpNgH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: create a symbolic link to a google drive workdir 'xyz' to the root of colab\n",
        "\n",
        "# Specify the path to your folder\n",
        "gdrive = '/content/drive/MyDrive/AI/2025'\n",
        "workdir = '/datasets'\n",
        "slink = '/content' + workdir\n",
        "fullpath = gdrive + workdir\n",
        "\n",
        "# Check if the folder exists\n",
        "if os.path.exists(fullpath):\n",
        "  # Create the symbolic link\n",
        "  try:\n",
        "    os.symlink(fullpath, slink)\n",
        "    print(f\"Symbolic link created from '{fullpath}' to '{slink}'\")\n",
        "  except FileExistsError:\n",
        "    print(f\"Symbolic link '{slink}' already exists.\")\n",
        "  except OSError as e:\n",
        "    print(f\"Error creating symbolic link: {e}\")\n",
        "else:\n",
        "  print(f\"Error: Folder '{fullpath}' not found.\")\n",
        "\n",
        "# !ls -lh /content"
      ],
      "metadata": {
        "id": "DZaxie5Coy46"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# !unzip datasets/datasets.zip -d datasets/\n",
        "# !rm datasets/datasets.zip"
      ],
      "metadata": {
        "id": "DeT28VMlqyZM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Notebook Start"
      ],
      "metadata": {
        "id": "yeq-lMpVrA4Y"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M_TzATjB-L2c"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import warnings\n",
        "\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "folder = './datasets/247/hourly/'\n",
        "\n",
        "df = pd.read_csv(folder + 'dataset.csv')\n",
        "df"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "date_column_name = df.columns[0]\n",
        "date_format = '%Y-%m-%d' if date_column_name.lower() == 'date' else '%Y-%m-%d %H:%M:%S'\n",
        "\n",
        "date_column_name, date_format"
      ],
      "metadata": {
        "id": "n_tpyIVT3leg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Converter a coluna para datetime removendo o fuso horário\n",
        "if date_column_name.lower() == 'date':\n",
        "    df[date_column_name] = pd.to_datetime(df[date_column_name])\n",
        "else:\n",
        "    df[date_column_name] = pd.to_datetime(df[date_column_name]).dt.tz_convert(None)\n",
        "\n",
        "df"
      ],
      "metadata": {
        "id": "fguoQooUAWlc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: plot df using plotly\n",
        "import plotly.express as px\n",
        "\n",
        "fig = px.line(df.drop('Real', axis=1), x=date_column_name, y=df.columns[2:])\n",
        "fig.show()"
      ],
      "metadata": {
        "id": "UN7ADtMkzHVd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2YHhQhQIoIGd"
      },
      "outputs": [],
      "source": [
        "split_date = pd.to_datetime('2024-08-26')\n",
        "#split_date = pd.to_datetime('2025-01-01')\n",
        "\n",
        "# Find the first row where the date is equal or greater than split_date\n",
        "def get_split_date_index(df, split_date):\n",
        "  for i in range(len(df)):\n",
        "    if df.iloc[i, 0] >= split_date:\n",
        "      return i\n",
        "\n",
        "split_idx = get_split_date_index(df, split_date)\n",
        "split_idx, df.iloc[split_idx, 0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AAUIJxqi-L2c"
      },
      "outputs": [],
      "source": [
        "# needed for dumb4cast\n",
        "df_train = df.iloc[:split_idx, :].drop('Real', axis=1)\n",
        "df_train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U1AcYR2s-L2c"
      },
      "outputs": [],
      "source": [
        "# needed for dumb4cast\n",
        "df_test = df.iloc[split_idx:, :].drop('Real', axis=1)\n",
        "df_test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i4TNMwYHQRAX"
      },
      "outputs": [],
      "source": [
        "# loading pre-trained model\n",
        "MODEL_NAMES = [\n",
        "    # 'arima',\n",
        "    'lstm',\n",
        "    'gru',\n",
        "    'mlp',\n",
        "    'dlinear',\n",
        "    'nlinear',\n",
        "    'informer',\n",
        "    'autoformer',\n",
        "    'fedformer',\n",
        "    'bitcn',\n",
        "    'rnn',\n",
        "\n",
        "    'tcn',\n",
        "    'deepar',\n",
        "    'dilatedrnn',\n",
        "    #'nbeats',\n",
        "    #'nbeatsx',\n",
        "    'nhits',\n",
        "    'tide',\n",
        "    'deepnpts',\n",
        "    'tft',\n",
        "    'vanilla',\n",
        "    'patchtst',\n",
        "    'itransformer',\n",
        "    #'timesnet'\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3T3sXPQ90mEe"
      },
      "outputs": [],
      "source": [
        "# prompt: add last row of df_train to a new test_df dataframe\n",
        "# Por que: o backtest precisa comparar os dados reais do dia anterior à previsão pra saber se compra ou vende\n",
        "real_column = df['Real'][split_idx-1:]\n",
        "test_df = df.iloc[split_idx-1:, :].drop('Real', axis=1)\n",
        "print(real_column)\n",
        "test_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OLn00bZQ-L2d"
      },
      "outputs": [],
      "source": [
        "forecasts = []\n",
        "\n",
        "for model_name in MODEL_NAMES:\n",
        "  print(f'Loading {model_name.upper()} forecasts')\n",
        "  forecast_df = pd.read_csv(folder + 'forecasts/forecast-' + model_name + '.csv')\n",
        "  forecasts.append(forecast_df[test_df.columns])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jQTOkbex9_Vu"
      },
      "outputs": [],
      "source": [
        "# creating a baseline buy-and-hold dataframe\n",
        "\n",
        "IB = 100.0 # initial balance for each asset\n",
        "\n",
        "# copy test_df to bh_df and set every value to zero\n",
        "bh_df = test_df.copy()\n",
        "for col in bh_df.columns[1:]:\n",
        "  bh_df[col] = 0\n",
        "bh_df[bh_df.columns[0]] = test_df[test_df.columns[0]]\n",
        "\n",
        "# except from the first column of bh_df, divide every other first row's value by IB (buying stocks)\n",
        "for j in range(1, len(test_df.columns)):\n",
        "  bh_df.iloc[0, j] = IB#test_df.iloc[0, j] / IB\n",
        "\n",
        "# calculating how much each stock would worth every day\n",
        "for i in range(1, len(test_df)):\n",
        "  for j in range(1, len(test_df.columns)):\n",
        "    bh_df.iloc[i, j] = bh_df.iloc[i-1, j] * (test_df.iloc[i, j] / test_df.iloc[i-1, j])\n",
        "\n",
        "bh_df.reset_index(drop=True, inplace=True)\n",
        "\n",
        "bh_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8Tbqkml6_Vs3"
      },
      "outputs": [],
      "source": [
        "# it looks all models prediction are just an one day shit from the real values.\n",
        "# dumb_4cast is a simple one day shit from test-data, so it'll force a buy transcation if the current\n",
        "# value had an increase compared to the previous day or sell if there was a drop of it's value.\n",
        "\n",
        "dumb_4cast = df_train.tail(2).copy()\n",
        "dumb_4cast = pd.concat([dumb_4cast, df_test[:-1]], ignore_index=True)\n",
        "dumb_4cast.reset_index(drop=True, inplace=True)\n",
        "\n",
        "# prompt: subtract one day for every value of column Date from dumb_4cast\n",
        "# convert it first\n",
        "dumb_4cast[date_column_name] = pd.to_datetime(dumb_4cast[date_column_name])\n",
        "\n",
        "if date_column_name.lower() == 'date':\n",
        "    dumb_4cast[date_column_name] = dumb_4cast[date_column_name] + pd.DateOffset(days=1)\n",
        "else:\n",
        "    dumb_4cast[date_column_name] = dumb_4cast[date_column_name] + pd.DateOffset(hours=1)\n",
        "\n",
        "# prompt: change dumb_4cast Date column back to string type\n",
        "dumb_4cast[date_column_name] = dumb_4cast[date_column_name].dt.strftime(date_format)\n",
        "\n",
        "dumb_4cast"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "MODEL_NAMES.append('dumb_4cast')\n",
        "forecasts.append(dumb_4cast)"
      ],
      "metadata": {
        "id": "iGuULhmbNtwH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PxFylKmkPTUU"
      },
      "outputs": [],
      "source": [
        "# prompt: create a second dataframe rev_df where the first column is the 'Date'\n",
        "# column of bh_df and the second column is the sum of every other value on each row\n",
        "#assets_count = len(test_df.columns) - 1 # except 'Date' column\n",
        "\n",
        "#rev_df = pd.DataFrame()\n",
        "#rev_df[date_column_name] = bh_df[date_column_name]\n",
        "#rev_df[\"Buy'n hold\"] = bh_df.iloc[:, 1:].sum(axis=1) / (assets_count)\n",
        "#rev_df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8yiGaMqmeOuy"
      },
      "source": [
        "Creating a dataframe with a wallet composed by the models predictions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6U-b8SH_eNtU"
      },
      "outputs": [],
      "source": [
        "def backtest(real_df, real_column, pred_df):\n",
        "  # copy real_df to model_df and set every value to zero\n",
        "  model_df = real_df.copy()\n",
        "  for col in model_df.columns[1:]:\n",
        "    model_df[col] = 0\n",
        "  model_df[model_df.columns[0]] = real_df[real_df.columns[0]]\n",
        "\n",
        "  model_df.reset_index(drop=True, inplace=True)\n",
        "\n",
        "  # except from the first column of model_df, divide every other first row's value by IB (buying stocks)\n",
        "  for j in range(1, len(real_df.columns)):\n",
        "    model_df.iloc[0, j] = IB\n",
        "\n",
        "  count = 0\n",
        "\n",
        "  # calculating how much each stock would worth every day\n",
        "  for i in range(1, len(real_df)):\n",
        "    if not real_column.iloc[i]: # don't backtest if market is closed (filled transaction, not real)\n",
        "      # copy previous row\n",
        "      model_df.iloc[i, 1:] = model_df.iloc[i-1, 1:]\n",
        "    else:\n",
        "      count += 1\n",
        "      for j in range(1, len(real_df.columns)):\n",
        "        if pred_df.iloc[i-1, j] > real_df.iloc[i-1, j]: # predicted value is higher than current value: buy\n",
        "          x = model_df.iloc[i-1, j] * (real_df.iloc[i, j] / real_df.iloc[i-1, j])\n",
        "        else:                                           # predicted value is lower than current value: sell\n",
        "          x = model_df.iloc[i-1, j] * (real_df.iloc[i-1, j] / real_df.iloc[i, j])\n",
        "\n",
        "        if x > 0:\n",
        "          model_df.iloc[i, j] = x\n",
        "        else:\n",
        "          model_df.iloc[i, j] = 0\n",
        "          break\n",
        "\n",
        "  print(f'\\t{count} predicted steps')\n",
        "\n",
        "  return model_df\n",
        "\n",
        "# i = 0\n",
        "# print(f'backtesting {MODEL_NAMES[i]}: ', end='')\n",
        "# backtest(test_df, real_column, forecasts[i])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: count how many True values are in real_column\n",
        "true_count = sum(real_column)\n",
        "print(f\"Number of True values in real_column: {true_count}\")"
      ],
      "metadata": {
        "id": "ISmZ8qg5DD2j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nZizHvf1ufxP"
      },
      "outputs": [],
      "source": [
        "%%time\n",
        "#rev2_df = rev_df.copy()\n",
        "\n",
        "backtests = [bh_df]\n",
        "\n",
        "for i in range(len(MODEL_NAMES)):\n",
        "  print(f'backtesting {MODEL_NAMES[i]}: ', end='')\n",
        "  model_rev_df = backtest(test_df, real_column, forecasts[i])\n",
        "  backtests.append(model_rev_df)\n",
        "  #rev2_df[MODEL_NAMES[i].upper()] = model_rev_df.iloc[:, 1:].sum(axis=1) / (assets_count)\n",
        "\n",
        "#rev2_df.tail(1)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: save all models in a 'backtest' folder inside workdir\n",
        "import os\n",
        "\n",
        "# Create the 'backtest' directory if it doesn't exist\n",
        "backtest_dir = os.path.join(folder, 'backtests')  # Use workdir variable\n",
        "os.makedirs(backtest_dir, exist_ok=True)\n",
        "\n",
        "# Save buy and hold and dumb4cast to the backtest folder\n",
        "bh_filename = os.path.join(backtest_dir, \"buy-and-hold.csv\")\n",
        "bh_df.to_csv(bh_filename, index=False)\n",
        "\n",
        "# Save each model's dataframe to a separate CSV file in the 'backtest' folder\n",
        "for i, model_name in enumerate(MODEL_NAMES):\n",
        "    filename = os.path.join(backtest_dir, f\"{model_name}.csv\")\n",
        "    backtests[i+1].to_csv(filename, index=False)  # i+1 to skip bh_df\n",
        "\n",
        "print(f\"Backtest results saved to '{backtest_dir}'\")"
      ],
      "metadata": {
        "id": "yQGE7nsfHF12"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7qykfIFbLV8K"
      },
      "outputs": [],
      "source": [
        "import IPython\n",
        "IPython.display.Audio(\"file_example_MP3_1MG.mp3\", autoplay=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2AgiqccI-L2e"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}