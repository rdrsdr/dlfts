{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#Setup google-drive mounting (optional)"
      ],
      "metadata": {
        "id": "HB-JD04Otxtf"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q_CZdAU6tiVr"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "import os\n",
        "\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: create a symbolic link to a google drive workdir 'xyz' to the root of colab\n",
        "\n",
        "# Specify the path to your folder\n",
        "gdrive = '/content/drive/MyDrive/AI/2025'\n",
        "workdir = '/datasets'\n",
        "slink = '/content' + workdir\n",
        "fullpath = gdrive + workdir\n",
        "\n",
        "# Check if the folder exists\n",
        "if os.path.exists(fullpath):\n",
        "  # Create the symbolic link\n",
        "  try:\n",
        "    os.symlink(fullpath, slink)\n",
        "    print(f\"Symbolic link created from '{fullpath}' to '{slink}'\")\n",
        "  except FileExistsError:\n",
        "    print(f\"Symbolic link '{slink}' already exists.\")\n",
        "  except OSError as e:\n",
        "    print(f\"Error creating symbolic link: {e}\")\n",
        "else:\n",
        "  print(f\"Error: Folder '{fullpath}' not found.\")\n",
        "\n",
        "# !ls -lh /content"
      ],
      "metadata": {
        "id": "zuybr3_2t01u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# !unzip datasets/datasets.zip -d datasets/\n",
        "# !rm datasets/datasets.zip"
      ],
      "metadata": {
        "id": "V4rchQuYuC2H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Loading real test dataset"
      ],
      "metadata": {
        "id": "61G27mtxuDw-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import warnings\n",
        "\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "folder = './datasets/247/hourly/'\n",
        "\n",
        "IB = 100.0 # initial balance for each asset\n",
        "#SPLIT_DATE = '2024-08-26'"
      ],
      "metadata": {
        "id": "nccOQK_DuFoM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Loading saved backtests"
      ],
      "metadata": {
        "id": "mo1MBBzSu48F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: load all saved backtests from folder into backtests list\n",
        "import os\n",
        "\n",
        "# Assuming 'backtests' is the directory containing the CSV files\n",
        "backtest_dir = os.path.join(folder, 'backtests')\n",
        "backtests = []\n",
        "titles = []\n",
        "\n",
        "# Iterate through the files in the directory\n",
        "for filename in os.listdir(backtest_dir):\n",
        "  if filename.endswith(\".csv\"):\n",
        "    filepath = os.path.join(backtest_dir, filename)\n",
        "    try:\n",
        "      # Read the CSV file into a Pandas DataFrame\n",
        "      df = pd.read_csv(filepath)\n",
        "      if (filename == 'buy-and-hold.csv'):\n",
        "        baseline = df\n",
        "        print(f\"Baseline loaded: {filename}\")\n",
        "      else:\n",
        "        backtests.append(df)\n",
        "        titles.append(filename.removesuffix('.csv').upper())\n",
        "        print()\n",
        "        print(f\"Backtest loaded: {filename}\")\n",
        "      display(df.iloc[:,1:21])\n",
        "    except pd.errors.EmptyDataError:\n",
        "      print(f\"Warning: Skipping empty file: {filename}\")\n",
        "    except pd.errors.ParserError:\n",
        "      print(f\"Warning: Skipping file with parsing error: {filename}\")"
      ],
      "metadata": {
        "id": "g2aNzXK3u7vo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "titles"
      ],
      "metadata": {
        "id": "FfyJaIL7jBL7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: generate a dataset based on df where each cell (except from datertime column) shows how much percent it has grown or reduced compared to the previous' row cell\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "def calculate_percentage_change(df):\n",
        "  \"\"\"Calculates the percentage change for each cell compared to the previous row.\n",
        "\n",
        "  Args:\n",
        "    df: The input DataFrame.\n",
        "\n",
        "  Returns:\n",
        "    A new DataFrame with percentage changes.\n",
        "  \"\"\"\n",
        "\n",
        "  # Create a copy to avoid modifying the original DataFrame\n",
        "  df_pct_change = df.copy()\n",
        "\n",
        "  # Iterate through columns (excluding the datetime column)\n",
        "  for col in df.columns[1:]:  # Assumes the first column is datetime\n",
        "    # Calculate percentage change for each cell\n",
        "    df_pct_change[col] = df[col].pct_change() * 100\n",
        "\n",
        "  # Fill first row with 100\n",
        "  df_pct_change.iloc[0, 1:] = 0\n",
        "\n",
        "  return df_pct_change"
      ],
      "metadata": {
        "id": "woJguw-vyEJt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "basedelta = calculate_percentage_change(baseline)\n",
        "deltas = []\n",
        "\n",
        "for backtest in backtests:\n",
        "  deltas.append(calculate_percentage_change(backtest))"
      ],
      "metadata": {
        "id": "CqgK2vkhxdbA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: function that gets two datasets, real and prediction, and returns a third one where each cell is calculated by the rules: ignore first column, absolute value of real cell, if real and prediction cells have different signals, change the signal. dont use iterrows()\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "def calculate_performance(real_df, prediction_df):\n",
        "    \"\"\"\n",
        "    Processes two datasets, real and prediction, according to the specified rules.\n",
        "\n",
        "    Args:\n",
        "        real_df: DataFrame representing the real data.\n",
        "        prediction_df: DataFrame representing the prediction data.\n",
        "\n",
        "    Returns:\n",
        "        A new DataFrame with the calculated values, or None if input DataFrames are invalid.\n",
        "    \"\"\"\n",
        "\n",
        "    # Input validation\n",
        "    if not isinstance(real_df, pd.DataFrame) or not isinstance(prediction_df, pd.DataFrame):\n",
        "        print(\"Error: Inputs must be pandas DataFrames.\")\n",
        "        return None\n",
        "\n",
        "    if real_df.shape != prediction_df.shape:\n",
        "      print(\"Error: DataFrames must have the same shape.\")\n",
        "      return None\n",
        "\n",
        "    if not all(real_df.columns == prediction_df.columns):\n",
        "      print(\"Error: DataFrames must have the same columns.\")\n",
        "      return None\n",
        "\n",
        "    # Create a copy to avoid modifying the original DataFrame\n",
        "    result_df = real_df.copy()\n",
        "\n",
        "    # Apply the rules to each column (excluding the first one)\n",
        "    for col in real_df.columns[1:]:\n",
        "        # Take the absolute value of real values\n",
        "        result_df[col] = np.abs(real_df[col])\n",
        "\n",
        "        # Identify cells with different signals\n",
        "        different_signals = np.sign(real_df[col]) != np.sign(prediction_df[col])\n",
        "\n",
        "        # Change the signal for cells with different signals\n",
        "        result_df.loc[different_signals, col] = -result_df.loc[different_signals, col]\n",
        "    return result_df\n",
        "\n",
        "baseline_idx = 0 # set to buy-ald-hold delta\n",
        "performances = []\n",
        "\n",
        "for i in range(len(deltas)):\n",
        "  print(f\"Calculating performance for {titles[i]}\")\n",
        "  performance_df = calculate_performance(basedelta, deltas[i])\n",
        "  performances.append(performance_df)\n",
        "  print(titles[i])\n",
        "  display(performances[i].iloc[:,1:21])"
      ],
      "metadata": {
        "id": "kcCZMl7o4c8b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: copy last row of wallet0 with title, sort it ascending, subtract each value from IB\n",
        "def sort_last_row(df, initial_balance_to_subtract):\n",
        "  last_row = df.tail(1).copy()\n",
        "  last_row_subtracted = last_row.iloc[:, 1:] - initial_balance_to_subtract\n",
        "  last_row_subtracted_t = last_row_subtracted.T\n",
        "  last_row_subtracted_sorted = last_row_subtracted_t.sort_values(by=last_row_subtracted_t.columns[0], ascending=True)\n",
        "  return last_row_subtracted_sorted.T"
      ],
      "metadata": {
        "id": "IJ25ffCjzfrr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: create heatmap from performance_df, positive values in blue, negative values in red\n",
        "\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "for i in range(len(performances)):\n",
        "  plt.figure(figsize=(20, 8))\n",
        "  sort = sort_last_row(performances[i].iloc[:, 1:], IB)\n",
        "  sns.heatmap(performances[i].iloc[:, 1:][sort.columns], annot=False, cmap=\"RdBu\", center=0) # Assuming the first column is an index\n",
        "  plt.title(f'{titles[i].upper()} Performance Heatmap')\n",
        "  plt.show()"
      ],
      "metadata": {
        "id": "dbjJpami_Peg"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}