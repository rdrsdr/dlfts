{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#Setup google-drive mounting (optional)"
      ],
      "metadata": {
        "id": "erlrIYB0q5v_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# from google.colab import drive\n",
        "# import os\n",
        "\n",
        "# drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "4Z3V2jwlpNgH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # prompt: create a symbolic link to a google drive workdir 'xyz' to the root of colab\n",
        "\n",
        "# # Specify the path to your folder\n",
        "# gdrive = '/content/drive/MyDrive/AI/2025'\n",
        "# workdir = '/datasets'\n",
        "# slink = '/content' + workdir\n",
        "# fullpath = gdrive + workdir\n",
        "\n",
        "# # Check if the folder exists\n",
        "# if os.path.exists(fullpath):\n",
        "#   # Create the symbolic link\n",
        "#   try:\n",
        "#     os.symlink(fullpath, slink)\n",
        "#     print(f\"Symbolic link created from '{fullpath}' to '{slink}'\")\n",
        "#   except FileExistsError:\n",
        "#     print(f\"Symbolic link '{slink}' already exists.\")\n",
        "#   except OSError as e:\n",
        "#     print(f\"Error creating symbolic link: {e}\")\n",
        "# else:\n",
        "#   print(f\"Error: Folder '{fullpath}' not found.\")\n",
        "\n",
        "# # !ls -lh /content"
      ],
      "metadata": {
        "id": "DZaxie5Coy46"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# !unzip datasets/datasets.zip -d ./\n",
        "# !rm datasets/datasets.zip"
      ],
      "metadata": {
        "id": "DeT28VMlqyZM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Loading real test dataset"
      ],
      "metadata": {
        "id": "QQYVr7L1Y-z4"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M_TzATjB-L2c"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import warnings\n",
        "\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "subset = '/crypto/hourly/'\n",
        "folder = './datasets' + subset\n",
        "\n",
        "IB = 100.0 # initial balance for each asset\n",
        "SPLIT_DATE = '2024-08-26'"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(folder + 'dataset.csv')\n",
        "df"
      ],
      "metadata": {
        "id": "RrhUiOLBq75-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "date_column_name = df.columns[0]\n",
        "date_format = '%Y-%m-%d' if date_column_name.lower() == 'date' else '%Y-%m-%d %H:%M:%S'\n",
        "\n",
        "date_column_name, date_format"
      ],
      "metadata": {
        "id": "Ad-OpuMvrLXH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Converter a coluna para datetime removendo o fuso horÃ¡rio\n",
        "if date_column_name.lower() == 'date':\n",
        "    df[date_column_name] = pd.to_datetime(df[date_column_name])\n",
        "else:\n",
        "    df[date_column_name] = pd.to_datetime(df[date_column_name]).dt.tz_convert(None)\n",
        "\n",
        "df"
      ],
      "metadata": {
        "id": "2nb1NDx_rPGl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "split_date = pd.to_datetime(SPLIT_DATE)\n",
        "\n",
        "# Find the first row where the date is equal or greater than split_date\n",
        "def get_split_date_index(df, split_date):\n",
        "  for i in range(len(df)):\n",
        "    if df.iloc[i, 0] >= split_date:\n",
        "      return i\n",
        "\n",
        "split_idx = get_split_date_index(df, split_date)\n",
        "split_idx, df.iloc[split_idx, 0]"
      ],
      "metadata": {
        "id": "up9J77MxtRWf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "split_idx += 17 # adjusting for other forecasts"
      ],
      "metadata": {
        "id": "4IROJH0vG57k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_test = df.iloc[split_idx-1:, :].drop('Real', axis=1)\n",
        "df_test"
      ],
      "metadata": {
        "id": "fNJiKYActVtr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Loading saved backtests for analysis"
      ],
      "metadata": {
        "id": "oDrlg2eZty-N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: load all saved backtests from folder into backtests list\n",
        "import os\n",
        "\n",
        "def load_backtests(path):\n",
        "  # Assuming 'backtests' is the directory containing the CSV files\n",
        "  backtest_dir = os.path.join(path, 'backtests')\n",
        "  backtests = []\n",
        "  titles = []\n",
        "  i = 0\n",
        "\n",
        "  # Iterate through the files in the directory\n",
        "  for filename in os.listdir(backtest_dir):\n",
        "    if filename.endswith(\".csv\"):\n",
        "      filepath = os.path.join(backtest_dir, filename)\n",
        "      try:\n",
        "        # Read the CSV file into a Pandas DataFrame\n",
        "        df = pd.read_csv(filepath)\n",
        "        backtests.append(df)\n",
        "        titles.append(filename.removesuffix('.csv'))\n",
        "        print(f\"Backtest loaded[{i}]: {filename}\")\n",
        "        i += 1\n",
        "      except pd.errors.EmptyDataError:\n",
        "        print(f\"Warning: Skipping empty file: {filename}\")\n",
        "      except pd.errors.ParserError:\n",
        "        print(f\"Warning: Skipping file with parsing error: {filename}\")\n",
        "\n",
        "  return backtests, titles"
      ],
      "metadata": {
        "id": "qPeM9qjD-yga"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# loading backtests without cross-validation\n",
        "backtests, titles = load_backtests(folder)"
      ],
      "metadata": {
        "id": "8ljaV_qXCHwL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# loading backtests with plain cross-validation (no refit)\n",
        "cross_plain_path = folder + 'cross-validation/plain/' # forecasts with cross-validation (no refit)\n",
        "# cross_refit_path # folder + 'cross-validation/refit/' # forecasts with cross-validation and refit\n",
        "\n",
        "plain_backtests, plain_titles = load_backtests(cross_plain_path)\n",
        "print(plain_titles)"
      ],
      "metadata": {
        "id": "fEN8iRCrDOqH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#cross_plain_path = folder + 'cross-validation/plain/' # forecasts with cross-validation (no refit)\n",
        "cross_plain_btc_path = folder + 'cross-validation/plain-btc/' # forecasts with cross-validation (no refit)\n",
        "# cross_refit_path # folder + 'cross-validation/refit/' # forecasts with cross-validation and refit\n",
        "\n",
        "plain_btc_backtests, plain_btc_titles = load_backtests(cross_plain_btc_path)\n",
        "print(plain_btc_titles)"
      ],
      "metadata": {
        "id": "ot-mdMreHiWE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# cross_plain_path = folder + 'cross-validation/plain/' # forecasts with cross-validation (no refit)\n",
        "# cross_plain_btc_path = folder + 'cross-validation/plain-btc/' # forecasts with cross-validation (no refit)\n",
        "cross_refit_path = folder + 'cross-validation/refit/' # forecasts with cross-validation and refit\n",
        "\n",
        "refit_backtests, refit_titles = load_backtests(cross_refit_path)\n",
        "print(plain_btc_titles)"
      ],
      "metadata": {
        "id": "uDPpioUWH2l4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# folder # './datasets/crypto/hourly/'\n",
        "# path # folder + 'forecasts/' # forecasts without cross-validation\n",
        "# cross_plain_path # folder + 'cross-validation/plain/' # forecasts with cross-validation (no refit)\n",
        "# cross_refit_path # folder + 'cross-validation/refit/' # forecasts with cross-validation and refit\n",
        "\n",
        "# df # original dataset loaded from .csv\n",
        "\n",
        "# date_column_name # 'Datetime' or 'Date'\n",
        "# date_format # '%Y-%m-%d' or '%Y-%m-%d %H:%M:%S'\n",
        "# split_idx # 11616 (index where training and testing datasets are split, separated by provided date)\n",
        "\n",
        "# df_test # df from split_idx dropped by column 'Real'\n",
        "\n",
        "# MODEL_NAMES # list of all used models (appended by 'dumb_4cast' later)\n",
        "\n",
        "# forecasts # forecasts without cross-validation\n",
        "# plain_forecasts # forecasts with cross-validation (no refit)\n",
        "# refit_forecasts # forecasts with cross-validation and refit\n",
        "\n",
        "# IB # 100.0 initial balance for each asset\n",
        "# SPLIT_DATE = '2024-08-26'\n",
        "\n",
        "# bh_df # baseline buy-and-hold dataframe\n",
        "# dumb_4cast # simple one day shit from df_train\n",
        "\n",
        "# backtests # backtests calculated from forecasts\n",
        "# plain_backtests # backtests calculated from plain_forecasts\n",
        "# refit_backtests # backtests calculated from refit_forecasts"
      ],
      "metadata": {
        "id": "4PB2fmfy_Kr-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "backtests[0]"
      ],
      "metadata": {
        "id": "53Ptap5oNDQ_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: create a dataframe btsums with same indexes of wallet[0] and one column for each entry in wallets\n",
        "\n",
        "# Assuming 'backtests' list is already populated as in the provided code\n",
        "# and 'wallet0' is correctly assigned to backtests[0].\n",
        "\n",
        "btsums = pd.DataFrame(index=backtests[0].index)  # Use wallet0's index\n",
        "btsums[date_column_name] = backtests[0][date_column_name]\n",
        "cols = len(backtests[0].columns) - 1\n",
        "\n",
        "for i, df in enumerate(backtests):\n",
        "    # Calculate the sum of all columns except the first one (date)\n",
        "    column_sum = df.iloc[:, 1:].sum(axis=1)\n",
        "    btsums[titles[i]] = column_sum / cols\n",
        "btsums"
      ],
      "metadata": {
        "id": "t-ZR1ZgOzRkD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: plot btsums in one line graph\n",
        "\n",
        "import plotly.graph_objects as go\n",
        "\n",
        "fig = go.Figure()\n",
        "\n",
        "for title in titles:\n",
        "    fig.add_trace(go.Scatter(x=btsums[date_column_name], y=btsums[title], mode='lines', name=title))\n",
        "\n",
        "fig.update_layout(title='BTSums One Line Graph',\n",
        "                  xaxis_title='Date',\n",
        "                  yaxis_title='Value')\n",
        "fig.show()"
      ],
      "metadata": {
        "id": "W1qSXvqh0zP1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: create a function to plot with plotly each dataset from backtests[], all columns of each one\n",
        "\n",
        "import plotly.graph_objects as go\n",
        "\n",
        "def plot_backtests(backtests, titles):\n",
        "  \"\"\"Plots each dataset from backtests[] using Plotly.\n",
        "\n",
        "  Args:\n",
        "      backtests: A list of pandas DataFrames.\n",
        "  \"\"\"\n",
        "\n",
        "  for i, df in enumerate(backtests):\n",
        "    fig = go.Figure()\n",
        "    for column in df.columns[1:]:  # Exclude the date column\n",
        "      fig.add_trace(go.Scatter(x=df[df.columns[0]], y=df[column], mode='lines', name=column))\n",
        "\n",
        "    fig.update_layout(title=f\"{titles[i].upper()}\", xaxis_title=\"Date\", yaxis_title=\"Value\")\n",
        "    fig.show()\n",
        "\n",
        "plot_backtests(backtests, titles)"
      ],
      "metadata": {
        "id": "XOLZ-f-M7EUz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: copy last row of wallet0 with title, sort it ascending, subtract each value from IB\n",
        "def sort_last_row(df, initial_balance_to_subtract):\n",
        "  last_row = df.tail(1).copy()\n",
        "  last_row_subtracted = last_row.iloc[:, 1:] - initial_balance_to_subtract\n",
        "  last_row_subtracted_t = last_row_subtracted.T\n",
        "  last_row_subtracted_sorted = last_row_subtracted_t.sort_values(by=last_row_subtracted_t.columns[0], ascending=True)\n",
        "  return last_row_subtracted_sorted.T"
      ],
      "metadata": {
        "id": "1KEhcPBp3m6u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: plot wallet0 in a bar graph using matplotlib, negative values on red, positive values on blue, create code as compact as possible\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Assuming wallet0 is a pandas DataFrame with column names as asset names\n",
        "# and the last row contains the final wallet values.\n",
        "\n",
        "def plot_bar(wallet, title):\n",
        "  # Extract the last row and remove the first column ('Date')\n",
        "  last_row = wallet.iloc[-1, 1:]\n",
        "\n",
        "  # Create a bar plot\n",
        "  plt.figure(figsize=(15, 5))\n",
        "  bars = plt.bar(last_row.index, last_row.values)\n",
        "\n",
        "  # Set colors based on positive or negative values\n",
        "  for bar, value in zip(bars, last_row.values):\n",
        "    if value < 0:\n",
        "      bar.set_color('red')\n",
        "    else:\n",
        "      bar.set_color('blue')\n",
        "\n",
        "  plt.xlabel('Assets')\n",
        "  plt.ylabel('Value')\n",
        "  plt.title(title)\n",
        "  plt.xticks(rotation=45, ha='right') # Rotate x-axis labels for better readability\n",
        "  plt.tight_layout() # Adjust layout to prevent labels from overlapping\n",
        "  plt.show()"
      ],
      "metadata": {
        "id": "Lzp85sizDRhH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(len(backtests)):\n",
        "  wallet = sort_last_row(backtests[i], IB)\n",
        "  display(wallet)\n",
        "  plot_bar(wallet, titles[i].upper())"
      ],
      "metadata": {
        "id": "QrAO6FUhETo2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: create a plotly animated bar graph over time from wallet, 30 frames per second\n",
        "\n",
        "import plotly.graph_objects as go\n",
        "\n",
        "# Assuming 'wallet0' DataFrame is already defined and contains a 'Date' column\n",
        "# and columns for each asset.\n",
        "\n",
        "idx = 5\n",
        "wallet_sorted = sort_last_row(backtests[idx], IB)\n",
        "wallet = backtests[idx][wallet_sorted.columns]\n",
        "\n",
        "# Prepare the data for animation\n",
        "frames = []\n",
        "for i in range(len(wallet)):\n",
        "    frame = go.Frame(\n",
        "        data=[go.Bar(x=wallet.columns[1:], y=wallet.iloc[i, 1:])],\n",
        "        name=str(i)  # Name each frame\n",
        "    )\n",
        "    frames.append(frame)\n",
        "\n",
        "# Create the initial figure\n",
        "fig = go.Figure(\n",
        "    data=[go.Bar(x=wallet.columns[1:], y=wallet.iloc[0, 1:])],\n",
        "    layout=go.Layout(\n",
        "        title=\"Wallet Animation\",\n",
        "        xaxis_title=\"Assets\",\n",
        "        yaxis_title=\"Value\",\n",
        "        updatemenus=[dict(\n",
        "            type=\"buttons\",\n",
        "            buttons=[dict(label=\"Play\",\n",
        "                          method=\"animate\",\n",
        "                          args=[None, {\"frame\": {\"duration\": 1, \"redraw\": True},\n",
        "                                       \"fromcurrent\": True, \"transition\": {\"duration\": 0}}])])]\n",
        "    ),\n",
        "    frames=frames\n",
        ")\n",
        "\n",
        "# Show the animated figure\n",
        "fig.show()"
      ],
      "metadata": {
        "id": "J9-H0u3tVrRB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2AgiqccI-L2e"
      },
      "outputs": [],
      "source": [
        "!pip install bar_chart_race"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import bar_chart_race as bcr\n",
        "\n",
        "idx = 3\n",
        "wallet = backtests[idx]\n",
        "#bcr.bar_chart_race(df=wallet.iloc[:,1:], filename='bar_chart_race_crypto_deepnpts.mp4')\n",
        "bcr.bar_chart_race(\n",
        "    df=wallet.iloc[:,1:],\n",
        "    filename='bcr' + subset.replace('/', '_') + titles[idx] + '.mp4',\n",
        "    title=titles[idx].upper() + ' Performance on ' + subset.replace('/', ' ').upper()  + ' Dataset',\n",
        "    period_length=50,         # 1500 ms / 50 = 30x faster\n",
        "    steps_per_period=10,      # fewer steps to keep pace smooth but fast\n",
        "    interpolate_period=True\n",
        ")"
      ],
      "metadata": {
        "id": "hRbW09iR14Xz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import IPython\n",
        "IPython.display.Audio(\"file_example_MP3_1MG.mp3\", autoplay=True)"
      ],
      "metadata": {
        "id": "fGAe2FflvluL"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}