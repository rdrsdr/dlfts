{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "soy6VfoLNvq8"
   },
   "source": [
    "https://nixtlaverse.nixtla.io/neuralforecast/docs/capabilities/cross_validation.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SVOZSKRi6Usq"
   },
   "outputs": [],
   "source": [
    "# !pip install neuralforecast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mY2NWJSg6hfo"
   },
   "outputs": [],
   "source": [
    "import logging\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from utilsforecast.plotting import plot_series\n",
    "\n",
    "from neuralforecast import NeuralForecast\n",
    "from neuralforecast.models import NHITS\n",
    "\n",
    "from neuralforecast.auto import AutoNHITS, AutoRNN, AutoLSTM, AutoGRU, AutoTCN, AutoDeepAR, AutoDilatedRNN, AutoBiTCN\n",
    "from neuralforecast.auto import AutoMLP, AutoNBEATS, AutoNBEATSx, AutoDLinear, AutoNLinear, AutoTiDE, AutoDeepNPTS\n",
    "from neuralforecast.auto import AutoTFT, AutoVanillaTransformer, AutoInformer, AutoAutoformer, AutoFEDformer\n",
    "from neuralforecast.auto import AutoPatchTST, AutoiTransformer, AutoTimesNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YLbLDzma6kfp"
   },
   "outputs": [],
   "source": [
    "import logging\n",
    "import os\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Change the default logging directory\n",
    "os.environ[\"LIGHTNING_LOGS_DIR\"] = \"/workdir/my_lightning_logs\"  # Or any other desired path\n",
    "\n",
    "logging.getLogger(\"pytorch_lightning\").setLevel(logging.ERROR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "16NjRoX76luq"
   },
   "outputs": [],
   "source": [
    "# Y_df = pd.read_parquet('https://datasets-nixtla.s3.amazonaws.com/m4-hourly.parquet')\n",
    "# Y_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zP0reHSKNIvW"
   },
   "outputs": [],
   "source": [
    "folder = './datasets/crypto/hourly/'\n",
    "\n",
    "df = pd.read_csv(folder + 'dataset.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "r19iS2HjOleV"
   },
   "outputs": [],
   "source": [
    "date_column_name = df.columns[0]\n",
    "date_format = '%Y-%m-%d' if date_column_name.lower() == 'date' else '%Y-%m-%d %H:%M:%S'\n",
    "\n",
    "date_column_name, date_format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0ConSOFdR-4d"
   },
   "outputs": [],
   "source": [
    "# Converter a coluna para datetime removendo o fuso horário\n",
    "if date_column_name.lower() == 'date':\n",
    "    df[date_column_name] = pd.to_datetime(df[date_column_name])\n",
    "else:\n",
    "    df[date_column_name] = pd.to_datetime(df[date_column_name]).dt.tz_convert(None)\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wv2SQmwhOGV5"
   },
   "outputs": [],
   "source": [
    "# pure pandas version (faster, more memory-friendly)\n",
    "def convert_nixtla(df):\n",
    "  # Convert from wide to long format\n",
    "  df_long = df.melt(id_vars=[date_column_name], var_name=\"ticker\", value_name=\"price\")\n",
    "\n",
    "  # Rename columns for Nixtla’s long format and return\n",
    "  return df_long.rename(columns={date_column_name: \"ds\", \"ticker\": \"unique_id\", \"price\": \"y\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "g8ffdAiSORZV"
   },
   "outputs": [],
   "source": [
    "Y_df = convert_nixtla(df.drop('Real', axis=1))\n",
    "Y_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "X7OethzaAAtL"
   },
   "outputs": [],
   "source": [
    "# Y_df = Y_df.query(\"unique_id == 'BTC-USD'\")#[:700]\n",
    "# Y_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ujUjIdWqARb9"
   },
   "outputs": [],
   "source": [
    "plot_series(Y_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "X1T3Dh8PUM4Q"
   },
   "outputs": [],
   "source": [
    "import neuralforecast.auto\n",
    "from neuralforecast.auto import AutoNHITS, AutoRNN, AutoLSTM, AutoGRU, AutoTCN, AutoDeepAR, AutoDilatedRNN, AutoBiTCN\n",
    "from neuralforecast.auto import AutoMLP, AutoNBEATS, AutoNBEATSx, AutoDLinear, AutoNLinear, AutoTiDE, AutoDeepNPTS\n",
    "from neuralforecast.auto import AutoTFT, AutoVanillaTransformer, AutoInformer, AutoAutoformer, AutoFEDformer\n",
    "from neuralforecast.auto import AutoPatchTST, AutoiTransformer, AutoTimesNet\n",
    "\n",
    "horizont = 1\n",
    "\n",
    "# --- CONFIGS ---\n",
    "\n",
    "# Extract the default hyperparameter settings\n",
    "\n",
    "#A. RNN-Based\n",
    "rnn_config = AutoRNN.get_default_config(h = horizont, backend=\"ray\")\n",
    "lstm_config = AutoLSTM.get_default_config(h = horizont, backend=\"ray\")\n",
    "gru_config = AutoGRU.get_default_config(h = horizont, backend=\"ray\")\n",
    "tcn_config = AutoTCN.get_default_config(h = horizont, backend=\"ray\")\n",
    "deep_ar_config = AutoDeepAR.get_default_config(h = horizont, backend=\"ray\")\n",
    "dilated_rnn_config = AutoDilatedRNN.get_default_config(h = horizont, backend=\"ray\")\n",
    "bitcn_config = AutoBiTCN.get_default_config(h = horizont, backend=\"ray\")\n",
    "\n",
    "#B. MLP-Based\n",
    "mlp_config = AutoMLP.get_default_config(h = horizont, backend=\"ray\")\n",
    "nbeats_config = AutoNBEATS.get_default_config(h = horizont, backend=\"ray\")\n",
    "nbeatsx_config = AutoNBEATSx.get_default_config(h = horizont, backend=\"ray\")\n",
    "nhits_config = AutoNHITS.get_default_config(h = horizont, backend=\"ray\")\n",
    "dlinear_config = AutoDLinear.get_default_config(h = horizont, backend=\"ray\")\n",
    "nlinear_config = AutoNLinear.get_default_config(h = horizont, backend=\"ray\")\n",
    "tide_config = AutoTiDE.get_default_config(h = horizont, backend=\"ray\")\n",
    "deep_npts_config = AutoDeepNPTS.get_default_config(h = horizont, backend=\"ray\")\n",
    "\n",
    "#C. Transformer models\n",
    "tft_config = AutoTFT.get_default_config(h = horizont, backend=\"ray\")\n",
    "vanilla_config = AutoVanillaTransformer.get_default_config(h = horizont, backend=\"ray\")\n",
    "informer_config = AutoInformer.get_default_config(h = horizont, backend=\"ray\")\n",
    "autoformer_config = AutoAutoformer.get_default_config(h = horizont, backend=\"ray\")\n",
    "fedformer_config = AutoFEDformer.get_default_config(h = horizont, backend=\"ray\")\n",
    "patch_tst_config = AutoPatchTST.get_default_config(h = horizont, backend=\"ray\")\n",
    "\n",
    "itransformer_config = AutoiTransformer.get_default_config(h = horizont, n_series=1, backend=\"ray\")\n",
    "\n",
    "#D. CNN Based\n",
    "timesnet_config = AutoTimesNet.get_default_config(h = horizont, backend=\"ray\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8ItFXXPDUO3p"
   },
   "outputs": [],
   "source": [
    "# --- MODELS ---\n",
    "#A. RNN-Based\n",
    "rnn_model = AutoRNN(h=horizont, config=rnn_config, verbose=False)\n",
    "lstm_model = AutoLSTM(h=horizont, config=lstm_config, verbose=False)\n",
    "gru_model = AutoGRU(h=horizont, config=gru_config, verbose=False)\n",
    "tcn_model = AutoTCN(h=horizont, config=tcn_config, verbose=False)\n",
    "deep_ar_model = AutoDeepAR(h=horizont, config=deep_ar_config, verbose=False)\n",
    "dilated_rnn_model = AutoDilatedRNN(h=horizont, config=dilated_rnn_config, verbose=False)\n",
    "bitcn_model = AutoBiTCN(h=horizont, config=bitcn_config, verbose=False)\n",
    "\n",
    "#B. MLP-Based\n",
    "mlp_model = AutoMLP(h=horizont, config=mlp_config, verbose=False)\n",
    "nbeats_model = AutoNBEATS(h=horizont, config=nbeats_config, verbose=False)\n",
    "nbeatsx_model = AutoNBEATSx(h=horizont, config=nbeats_config, verbose=False)\n",
    "nhits_model = AutoNHITS(h=horizont, config=nhits_config, verbose=False)\n",
    "dlinear_model = AutoDLinear(h=horizont, config=dlinear_config, verbose=False)\n",
    "nlinear_model = AutoNLinear(h=horizont, config=nlinear_config, verbose=False)\n",
    "tide_model = AutoTiDE(h=horizont, config=tide_config, verbose=False)\n",
    "deep_npts_model = AutoDeepNPTS(h=horizont, config=deep_npts_config, verbose=False)\n",
    "\n",
    "#C. Transformer models\n",
    "tft_model = AutoTFT(h=horizont, config=tft_config, verbose=False)\n",
    "vanilla_model = AutoVanillaTransformer(h=horizont, config=vanilla_config, verbose=False)\n",
    "informer_model = AutoInformer(h=horizont, config=informer_config, verbose=False)\n",
    "autoformer_model = AutoAutoformer(h=horizont, config=autoformer_config, verbose=False)\n",
    "fedformer_model = AutoFEDformer(h=horizont, config=fedformer_config, verbose=False)\n",
    "patch_tst_model = AutoPatchTST(h=horizont, config=patch_tst_config, verbose=False)\n",
    "\n",
    "itransformer_model = AutoiTransformer(h=horizont, n_series=1, config=itransformer_config, verbose=False)\n",
    "\n",
    "#D. CNN Based\n",
    "timesnet_model = AutoTimesNet(h=horizont, config=timesnet_config, verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_NAMES = [\n",
    "    # 'lstm',\n",
    "    # 'gru',\n",
    "    # 'mlp',\n",
    "    # 'dlinear',\n",
    "    # 'nlinear',\n",
    "    # 'informer',\n",
    "    # 'autoformer',\n",
    "    # 'fedformer',\n",
    "    'bitcn',\n",
    "    'rnn',\n",
    "\n",
    "    'tcn',\n",
    "    'deep_ar',\n",
    "    'dilated_rnn',\n",
    "    #nbeats,\n",
    "    #nbeatsx,\n",
    "    'nhits',\n",
    "    'tide',\n",
    "    'deep_npts',\n",
    "    'tft',\n",
    "    'vanilla',\n",
    "    'patch_tst',\n",
    "    'itransformer'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NXQjiJr7wDff"
   },
   "outputs": [],
   "source": [
    "models = [\n",
    "    # lstm_model,\n",
    "    # gru_model,\n",
    "    # mlp_model,\n",
    "    # dlinear_model,\n",
    "    # nlinear_model,\n",
    "    # informer_model,\n",
    "    # autoformer_model,\n",
    "    # fedformer_model,\n",
    "    bitcn_model,\n",
    "    rnn_model,\n",
    "\n",
    "    tcn_model,\n",
    "    deep_ar_model,\n",
    "    dilated_rnn_model,\n",
    "    #nbeats,\n",
    "    #nbeatsx,\n",
    "    nhits_model,\n",
    "    tide_model,\n",
    "    deep_npts_model,\n",
    "    tft_model,\n",
    "    vanilla_model,\n",
    "    patch_tst_model,\n",
    "    itransformer_model\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "L4K7H0RkCGaA",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# %%time\n",
    "# # training each model individually\n",
    "# import logging\n",
    "\n",
    "# # Configure logging\n",
    "# logging.basicConfig(filename='cross_logs.txt', level=logging.INFO, filemode='w')\n",
    "\n",
    "# h = horizont\n",
    "# n_windows=5888\n",
    "# #refit=False\n",
    "# refit=24*30 #refit every 30 days\n",
    "# nfs = []\n",
    "# cv_dfs = []\n",
    "\n",
    "# for model in models:\n",
    "#     logging.info(f\"Starting cross validation for model {type(model)}\")\n",
    "#     nf = NeuralForecast(models=[model], freq='h');\n",
    "\n",
    "#     try:\n",
    "#       cv_df = nf.cross_validation(Y_df, n_windows=n_windows, step_size=h, refit=refit)\n",
    "#       cv_dfs.append(cv_df)\n",
    "#       nfs.append(nf)\n",
    "#       logging.info(f\"Finished cross validation of model {type(model)}\")\n",
    "#     except Exception as e:\n",
    "#       logging.error(f\"Error in cross validation for model {type(model)}: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#folder = './datasets/crypto/hourly/'\n",
    "cross_folder = folder + '/cross-validation/plain'\n",
    "refit_folder = folder + '/cross-validation/refit'\n",
    "output_folder = refit_folder\n",
    "model_folder = '/models/'\n",
    "forecast_folder = '/forecasts/'\n",
    "\n",
    "os.makedirs(output_folder + forecast_folder, exist_ok=True)\n",
    "\n",
    "# for i in range(len(models)):\n",
    "#     nfs[i].save(output_folder + model_folder + MODEL_NAMES[i].lower(), overwrite=True)\n",
    "#     cv_dfs[i].to_csv(output_folder + forecast_folder + MODEL_NAMES[i] + '.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "# training each model individually\n",
    "import logging\n",
    "\n",
    "# Configure logging\n",
    "logging.basicConfig(filename='cross_logs.txt', level=logging.INFO, filemode='w')\n",
    "\n",
    "h = horizont\n",
    "n_windows=5888\n",
    "#refit=False\n",
    "refit=24*30 #refit every 30 days\n",
    "nfs = []\n",
    "cv_dfs = []\n",
    "\n",
    "# for model in models:\n",
    "for i in range(len(models)):\n",
    "    logging.info(f\"Starting cross validation for model {type(models[i])}\")\n",
    "    nf = NeuralForecast(models=[models[i]], freq='h');\n",
    "\n",
    "    try:\n",
    "      cv_df = nf.cross_validation(Y_df, n_windows=n_windows, step_size=h, refit=refit)\n",
    "      cv_dfs.append(cv_df)\n",
    "      nfs.append(nf)\n",
    "      nfs[i].save(output_folder + model_folder + MODEL_NAMES[i].lower(), overwrite=True)\n",
    "      cv_dfs[i].to_csv(output_folder + forecast_folder + MODEL_NAMES[i] + '.csv', index=False)\n",
    "      logging.info(f\"Finished cross validation of model {type(models[i])}\")\n",
    "    except Exception as e:\n",
    "      logging.error(f\"Error in cross validation for model {type(models[i])}: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import IPython\n",
    "IPython.display.Audio(\"file_example_MP3_1MG.mp3\", autoplay=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "we5nUPWK_qOZ",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "# training all models together\n",
    "h = horizont\n",
    "n_windows=5888\n",
    "\n",
    "nf = NeuralForecast(models=models, freq='h');\n",
    "cv_df = nf.cross_validation(Y_df, n_windows=n_windows, step_size=h)\n",
    "\n",
    "nf.save(cross_folder + model_folder + 'ALL', overwrite=True)\n",
    "cv_df.to_csv(cross_folder + forecast_folder + 'ALL.csv', index=False)\n",
    "\n",
    "cv_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xwl3gkJINPuN"
   },
   "outputs": [],
   "source": [
    "cutoffs = cv_df['cutoff'].unique()\n",
    "\n",
    "model_name = 'AutoLSTM'\n",
    "\n",
    "plt.figure(figsize=(15,5))\n",
    "plt.xlim('2024-08-26 17:00:00', '2025-04-29 00:00:00')\n",
    "plt.plot(Y_df['ds'], Y_df['y'])\n",
    "plt.plot(cv_df['ds'], ls='--')\n",
    "\n",
    "for cutoff in cutoffs:\n",
    "    plt.axvline(x=cutoff, color='black', ls=':')\n",
    "\n",
    "plt.xlabel('Time steps')\n",
    "plt.ylabel('Target')\n",
    "plt.legend()\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cs-8cJw0NTW_"
   },
   "outputs": [],
   "source": [
    "# cv_df_val_test = nf.cross_validation(Y_df, val_size=2000, test_size=200, step_size=h, n_windows=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aP21mqNGNZBh"
   },
   "outputs": [],
   "source": [
    "# cutoffs = cv_df_val_test['cutoff'].unique()\n",
    "# plt.figure(figsize=(15,5))\n",
    "\n",
    "# # Plot the original data and NHITS predictions\n",
    "# plt.plot(Y_df['ds'], Y_df['y'])\n",
    "# plt.plot(cv_df_val_test['ds'], cv_df_val_test[model_name], label=model_name, ls='--')\n",
    "\n",
    "# # Add highlighted areas for validation and test sets\n",
    "# plt.axvspan(Y_df['ds'].iloc[300], Y_df['ds'].iloc[499], alpha=0.2, color='yellow', label='Validation Set')\n",
    "# plt.axvspan(Y_df['ds'].iloc[500], Y_df['ds'].iloc[699], alpha=0.2, color='red', label='Test Set')\n",
    "\n",
    "# # Add vertical lines for cutoffs\n",
    "# for cutoff in cutoffs:\n",
    "#     plt.axvline(x=cutoff, color='black', ls=':')\n",
    "\n",
    "# # Set labels and legend\n",
    "# plt.xlabel('Time steps')\n",
    "# plt.ylabel('Target [H1]')\n",
    "# plt.legend()\n",
    "\n",
    "# plt.tight_layout()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "D2tddz2GNc7h",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "refit=24*7 # refit every week\n",
    "cv_df_refit = nf.cross_validation(Y_df, n_windows=n_windows, step_size=h, refit=refit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CrWzUf7BNfGi"
   },
   "outputs": [],
   "source": [
    "cutoffs = cv_df_refit['cutoff'].unique()\n",
    "\n",
    "plt.figure(figsize=(15,5))\n",
    "plt.plot(Y_df['ds'], Y_df['y'])\n",
    "plt.plot(cv_df_refit['ds'], cv_df_refit[model_name], label=model_name, ls='--')\n",
    "\n",
    "for cutoff in cutoffs:\n",
    "    plt.axvline(x=cutoff, color='black', ls=':')\n",
    "\n",
    "plt.xlabel('Time steps')\n",
    "plt.ylabel('Target [H1]')\n",
    "plt.legend()\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PjMsA55Lvg2n"
   },
   "outputs": [],
   "source": [
    "stop here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "L9udSZeBNnlD"
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "cv_df_refit_overlap = nf.cross_validation(Y_df, n_windows=2, step_size=h, refit=refit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NqsnWytmnRI4"
   },
   "outputs": [],
   "source": [
    "cutoffs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aoF6UGS3nqdR"
   },
   "outputs": [],
   "source": [
    "cutoffs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IcVq0KUwNo-b"
   },
   "outputs": [],
   "source": [
    "cutoffs = cv_df_refit_overlap['cutoff'].unique()\n",
    "\n",
    "fold1 = cv_df_refit_overlap.query(cutoffs[0].strftime('%Y-%m-%d %H:%M:%S'))\n",
    "fold2 = cv_df_refit_overlap.query(cutoffs[1].strftime('%Y-%m-%d %H:%M:%S'))\n",
    "\n",
    "plt.figure(figsize=(15,5))\n",
    "plt.plot(Y_df['ds'], Y_df['y'])\n",
    "plt.plot(fold1['ds'], fold1[model_name], label=model_name+' (fold 1)', ls='--', color='blue')\n",
    "plt.plot(fold2['ds'], fold2[model_name], label=model_name+' (fold 2)', ls='-.', color='red')\n",
    "\n",
    "for cutoff in cutoffs:\n",
    "    plt.axvline(x=cutoff, color='black', ls=':')\n",
    "\n",
    "plt.xlabel('Time steps')\n",
    "#plt.ylabel('Target [H1]')\n",
    "plt.xlim(500, 700)\n",
    "plt.legend()\n",
    "plt.tight_layout()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
